\input{prelude.tex}
\input{config.tex}


%%%%%%%%%%%%%%%%% END OF PREAMBLE %%%%%%%%%%%%%%%%

\begin{document}
\maketitle

%\include{Sections/Introduzione.tex}
%\include{Section2}
%\include{Section3}
%\include{Section4}
%\include{Conclusion}

%*******    Figure and Subfigure example ***********
%\begin{figure}[tbh]
% \includegraphics[width=1\linewidth]{circle}
% \caption[Circonferenza]{Circle}
% \label{fig:circle}
% \end{figure}%

% \begin{figure}[tbh]
% \begin{subfigure}{.5\textwidth}
% \includegraphics[width=1\linewidth]{circle}
% \caption[Circonferenza]{Circle}
% \label{fig:circle}
% \end{subfigure}%
% \begin{subfigure}{0.5\textwidth}
% \includegraphics[width=1\linewidth]{random}
% \caption[Random]{Random}
% \label{fig:random}
% \end{subfigure}
% \end{figure}
%%%***************************************%%

\section{Answers to the Questions}


\clearpage

%\bibbycategory % equivale a dare un \printbibliography per ogni categoria

Q-B: If 20 different clients try to connect our server some of the connection attempt could get rejected if the set backlog is too small. The backlog indicate the maximum number of allowed pending requests (requests that have been received by the network stack but are not yet accepted by a process). When the backlog queue is full, new requests are discarded by the network stack and are lost. The iterative server is the worst because before accepting another connection has to finalize the current one. Since all the 20 requests come at the same time, while the server process the first, the others go into the backlog queue. If the backlog value is set less than 20 (like in our case where we use 5), connections attempt will probably be dropped. The preforking server avoids this problem by assigning a new process at each new connection, so when one is processed, the server can wait for another one with the call to \texttt{accept}. Since we have 10 preforked processes, the first 10 connection will be accepted while other 5 can be in the backlog queue. If the time in which requests are processed is long and the request comes near each other, it's possible to lose some connection attempt (but fewer than for the iterative server). The one process per connection server works the same way as the preforked version but adds a little initial delay for the creation of the processes, so it will performs slightly worse in this case.

Q-C: The problem is that we have to modify the counter from different processes, so counter needs to be a shared variable. To avoid race condition when accessing the variable, we use a semaphore to protect the operation of incrementing the counter, which is critic section of the code. In this way only one process at a time can write the value of counter. A different approach could be to increment the counter in the parent process (so only one process modify this variable) and communicate the new value to the children processes.

Q-D: Yes, the problem is the same because multiple processes need to change the value of the same variable, the only difference is when the process are created. A semaphore is a correct solution because the shared variable will be accessed in mutual exclusion, so the operation of reading and increasing the value of the counter can be done without other processes interfering. The second approach (the parent keeps the counter and the children communicates with the parent process) is also applicable, but it needs a different implementation. In this case, since it's the children that process the requests, the parent will have to wait to read in a common file descriptor that every child can use to communicate and retrieve the new value of counter. To prevent overlapping in the access to the common communication channel we need to have access in mutual exclusion with a semaphore.
Approach one is applicable also to this version of the server, while the second approach no because the parent after have preforked his childs doesn't deal with the request of communications. 


(we have to add mutex on accept for preforking -> no waste of time)

Q-D: Which kind of server more appropriate for talk? iterative, one per, pref, why
The most appropriate server mode is the preforking because we have to manage both the send and the recieve of messages. Two processes are needed and knowing in advance the number of needed processes it is more convenient to use a preforking approach.


Q-D: The talk server needs to wait for two different type of events at the same time: the input from the local client and a message coming from remote, with different type of actions to perform. This can't be done in an iterative way (that is used to respond to the same type of requests). The one process per client would work but there is no need to create new processes on every connections if we assume that only one client is connected at a time. The preforked mode (with two processes, one for waiting messages on the connection, the other for the user input) is ideal for this situation, because all the preforked processes are used to their maximum.

Q-E: Yes, we can do that in both cases. When a TCP connection is created, it uses the combination (srcIP, srcPORT, dstIP,dstPORT) to direct the messages to the right listening process. So if the clients that connects to a \texttt{talk} server use different ports (destination ports), even if they have the the same IP address and destination IP/Port, the network stack is able to deliver the messages to the correct server. So once the connections are created, we can run multiple client/server and multiple servers on the same machine. One problem could be the binding of multiple servers (the second problem) to the same IP/Port (that gives the error \texttt{EADDRINUSE}), which can be solved with the options \texttt{SO\_REUSEADDR} and \texttt{SO\_REUSEPORT} during the binding of the socket.
Q-E: Yes, we can run two instances of the program on the same machine for both (a) and (b) options. Messages will be sent correctly and the right combination (server-client) will be created looking on the tuple (srcIP, srcPORT, dstIP,dstPORT) that is unique for every TCP connection.

Q-F
Q-F: a) With only one process/thread it is possible to use the select statement to avoid the blocking read. 
b) One process/thread manage the read and another one the write, so only one process is blocked on the read statement.
We have used the second approach.

\end{document}
